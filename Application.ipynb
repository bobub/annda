{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: create targets for the patterns\n",
    "\n",
    "def lin_sep_data(n=100, mA=np.array([1.5,1.5]), mB=np.array([-1.5,-1.5]), sigmaA=0.5, sigmaB=0.5):\n",
    "    \"\"\"\n",
    "    Creates 2 class lin sep dataset.\n",
    "    \n",
    "    Inputs:\n",
    "    n = samples (must be even number)\n",
    "    mA = mean of distrbution A\n",
    "    mB = ___________________ B\n",
    "    sigmaA = std. dev of A\n",
    "    sigmaB = ___________ B\n",
    "    \n",
    "    Outputs:\n",
    "    data = linearly separable dataset, where last column is targets (class), rest is patterns(features)\n",
    "    \"\"\"\n",
    "    \n",
    "    #keep making datasets until lin sep dataset is made ; will enter infinite loop if you choose shitty mean and sigmas\n",
    "    separable = False\n",
    "    while not separable:\n",
    "        \n",
    "        #create data\n",
    "        A = np.array([np.random.normal(mA[0],sigmaA,(n//2,1)), np.random.normal(mA[1],sigmaA,(n//2,1))]).reshape(n//2,2)\n",
    "        A = np.append(A,np.ones((n//2,1)),axis=1) # add targets\n",
    "        B = np.array([np.random.normal(mB[0],sigmaB,(n//2,1)), np.random.normal(mB[1],sigmaB,(n//2,1))]).reshape(n//2,2)\n",
    "        B = np.append(B,np.ones((n//2,1))*-1,axis=1) # add targets\n",
    "        \n",
    "        print(A.shape)\n",
    "        print(B.shape)\n",
    "        \n",
    "        #only checks for vertical or horizontal separability\n",
    "        separable = any([A[:, k].max() < B[:, k].min() or A[:, k].min() > B[:, k].max() for k in range(2)])\n",
    "        \n",
    "    #shuffle samples\n",
    "    data = np.append(A,B,axis=0)\n",
    "    data = np.random.shuffle(np.append(A,B,axis=0))\n",
    "    \n",
    "    #visualise\n",
    "    plt.plot(A[:, 0], A[:, 1], 'r.',label='class A')\n",
    "    plt.plot(B[:, 0], B[:, 1], 'b.',label='class B')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n",
      "(50, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "data = lin_sep_data()\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-23-4f1ea4d344f2>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-4f1ea4d344f2>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    def __init__():\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class single_layered_perceptron():\n",
    "    \"\"\"\n",
    "    Creates a single layer perceptron with 2 inputs and 2 outputs. \n",
    "    Change layers and weight&bias initialisation shapes for other input/output dimensions.\n",
    "    \n",
    "    Inputs:\n",
    "    layers = [input,output]\n",
    "    update = 'batch' or 'sequential' learning\n",
    "    learning = 'delta' rule or 'perceptron' rule\n",
    "    lr = learning rate\n",
    "    weights = init by randomly sampled around 0 with std dev 1\n",
    "    bias = init as 0s\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers=[2,2], lr=.1, update='batch', learning='perceptron', weights=np.random.normal(0,1,(2,2)), bias=np.zeros((1,2))):\n",
    "        \n",
    "        self.layers=layers\n",
    "        self.lr=.1\n",
    "        self.learning=learning\n",
    "        self.update = update\n",
    "        self.weights = np.append(weights,bias,axis=0) #biases are last weight matrix entry\n",
    "    \n",
    "    def batch(self):\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network():\n",
    "    def __init__(self, layers=[2, 100, 2], scale=.1, p=.1, lr=.1, lam=.1):\n",
    "        super().__init__()\n",
    "        self.weights = tr.nn.ParameterList([tr.nn.Parameter(scale * tr.randn(m, n)) for m, n in zip(layers[:-1], layers[1:])])\n",
    "        self.biases = tr.nn.ParameterList([tr.nn.Parameter(scale * tr.randn(n)) for n in layers[1:]])\n",
    "        self.parameters = list(self.weights) + list(self.biases)\n",
    "\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        self.lam = lam\n",
    "        self.train = False\n",
    "\n",
    "    def relu(self, X, W, b):\n",
    "        # algorithm 15, pg 46 from guide.pdf\n",
    "        if self.train:\n",
    "            delta = bernoulli.rvs(1 - self.p,\n",
    "                                  size=W.shape[1])  # sample 'out' many samples from Bernoulli distribution B(1-p)\n",
    "            Z = tr.from_numpy(delta) * tr.max(tr.zeros(X.shape[0], W.shape[1]), tr.mm(X, W) + b)\n",
    "\n",
    "        else:\n",
    "            Z = tr.max(tr.zeros(X.shape[0], W.shape[1]), (1 - self.p) * tr.mm(X, W) + b)\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def softmax(self, Z, W, b):\n",
    "        # algorithm 16, pg 46 from guide.pdf\n",
    "        Z = tr.mm(Z, W) + b\n",
    "        y_hat = tr.div(tr.exp(Z).T, tr.sum(tr.exp(Z), dim=1)).T\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def forward(self, X):\n",
    "        # algorithm 14, pg 45 from guide.pdf\n",
    "        X = tr.tensor(X, dtype=tr.float)\n",
    "        Z = X\n",
    "        # apply ReLU to all layers but the last\n",
    "        for w, b in zip(self.weights[:len(self.weights) - 1],\n",
    "                        self.biases[:len(self.biases) - 1]):  # iterate through L-1 layers\n",
    "            Z = self.relu(Z, w, b)\n",
    "        # apply softmax to last layer\n",
    "        y_hat = self.softmax(Z, self.weights[len(self.weights) - 1], self.biases[len(self.biases) - 1])\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X).detach().numpy()\n",
    "\n",
    "    def loss(self, ypred, ytrue):\n",
    "        # compute cross entropy loss according to pg47 from guide.pdf\n",
    "        loss = (-1 / ytrue.shape[0]) * tr.sum(ytrue * tr.log(ypred))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, y, nsteps=1000, bs=100, plot=False):\n",
    "        X, y = tr.tensor(X), tr.tensor(y)\n",
    "        optimizer = tr.optim.SGD(self.parameters, lr=self.lr, weight_decay=self.lam)\n",
    "\n",
    "        I = tr.randperm(X.shape[0])\n",
    "        n = int(np.ceil(.1 * X.shape[0]))\n",
    "        Xtrain, ytrain = X[I[:n]], y[I[:n]]\n",
    "        Xval, yval = X[I[n:]], y[I[n:]]\n",
    "\n",
    "        Ltrain, Lval, Aval = [], [], []\n",
    "        for i in range(nsteps):\n",
    "            optimizer.zero_grad()\n",
    "            I = tr.randperm(Xtrain.shape[0])[:bs]\n",
    "            self.train = True\n",
    "            output = self.loss(self.forward(Xtrain[I]), ytrain[I])\n",
    "            self.train = False\n",
    "            Ltrain += [output.item()]\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outval = self.forward(Xval)\n",
    "            Lval += [self.loss(outval, yval).item()]\n",
    "            Aval += [np.array(outval.argmax(-1) == yval.argmax(-1)).mean()]\n",
    "\n",
    "        if plot:\n",
    "            plt.plot(range(nsteps), Ltrain, label='Training loss')\n",
    "            plt.plot(range(nsteps), Lval, label='Validation loss')\n",
    "            plt.plot(range(nsteps), Aval, label='Validation acc')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
